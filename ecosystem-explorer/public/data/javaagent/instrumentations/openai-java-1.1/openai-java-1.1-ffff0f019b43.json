{
  "configurations": [
    {
      "default": false,
      "description": "Enables including the full content of user and assistant messages in emitted log events. Note that full content can have data privacy and size concerns, and care should be taken when enabling this.",
      "name": "otel.instrumentation.genai.capture-message-content",
      "type": "boolean"
    }
  ],
  "description": "This instrumentation enables Gen AI client spans and metrics for the OpenAI Java SDK.",
  "display_name": "OpenAI Java SDK",
  "has_standalone_library": true,
  "javaagent_target_versions": [
    "com.openai:openai-java:[1.1.0,3)"
  ],
  "library_link": "https://github.com/openai/openai-java",
  "name": "openai-java-1.1",
  "scope": {
    "name": "io.opentelemetry.openai-java-1.1"
  },
  "semantic_conventions": [
    "GENAI_CLIENT_SPANS",
    "GENAI_CLIENT_METRICS"
  ],
  "source_path": "instrumentation/openai/openai-java-1.1",
  "tags": [
    "openai"
  ],
  "telemetry": [
    {
      "metrics": [
        {
          "attributes": [
            {
              "name": "gen_ai.operation.name",
              "type": "STRING"
            },
            {
              "name": "gen_ai.provider.name",
              "type": "STRING"
            },
            {
              "name": "gen_ai.request.model",
              "type": "STRING"
            },
            {
              "name": "gen_ai.response.model",
              "type": "STRING"
            }
          ],
          "description": "GenAI operation duration.",
          "name": "gen_ai.client.operation.duration",
          "type": "HISTOGRAM",
          "unit": "s"
        },
        {
          "attributes": [
            {
              "name": "gen_ai.operation.name",
              "type": "STRING"
            },
            {
              "name": "gen_ai.provider.name",
              "type": "STRING"
            },
            {
              "name": "gen_ai.request.model",
              "type": "STRING"
            },
            {
              "name": "gen_ai.response.model",
              "type": "STRING"
            },
            {
              "name": "gen_ai.token.type",
              "type": "STRING"
            }
          ],
          "description": "Measures number of input and output tokens used.",
          "name": "gen_ai.client.token.usage",
          "type": "HISTOGRAM",
          "unit": "token"
        }
      ],
      "spans": [
        {
          "attributes": [
            {
              "name": "gen_ai.operation.name",
              "type": "STRING"
            },
            {
              "name": "gen_ai.provider.name",
              "type": "STRING"
            },
            {
              "name": "gen_ai.request.encoding_formats",
              "type": "STRING_ARRAY"
            },
            {
              "name": "gen_ai.request.model",
              "type": "STRING"
            },
            {
              "name": "gen_ai.response.model",
              "type": "STRING"
            },
            {
              "name": "gen_ai.usage.input_tokens",
              "type": "LONG"
            }
          ],
          "span_kind": "CLIENT"
        },
        {
          "attributes": [
            {
              "name": "gen_ai.operation.name",
              "type": "STRING"
            },
            {
              "name": "gen_ai.provider.name",
              "type": "STRING"
            },
            {
              "name": "gen_ai.request.frequency_penalty",
              "type": "DOUBLE"
            },
            {
              "name": "gen_ai.request.max_tokens",
              "type": "LONG"
            },
            {
              "name": "gen_ai.request.model",
              "type": "STRING"
            },
            {
              "name": "gen_ai.request.presence_penalty",
              "type": "DOUBLE"
            },
            {
              "name": "gen_ai.request.seed",
              "type": "LONG"
            },
            {
              "name": "gen_ai.request.stop_sequences",
              "type": "STRING_ARRAY"
            },
            {
              "name": "gen_ai.request.temperature",
              "type": "DOUBLE"
            },
            {
              "name": "gen_ai.request.top_p",
              "type": "DOUBLE"
            },
            {
              "name": "gen_ai.response.finish_reasons",
              "type": "STRING_ARRAY"
            },
            {
              "name": "gen_ai.response.id",
              "type": "STRING"
            },
            {
              "name": "gen_ai.response.model",
              "type": "STRING"
            },
            {
              "name": "gen_ai.usage.input_tokens",
              "type": "LONG"
            },
            {
              "name": "gen_ai.usage.output_tokens",
              "type": "LONG"
            }
          ],
          "span_kind": "INTERNAL"
        }
      ],
      "when": "default"
    }
  ]
}